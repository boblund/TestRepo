<!DOCTYPE html>
<html>
  <head>
    <title>Sourcing In-band Media Resource Tracks from Media Containers into HTML</title>
    <meta charset='utf-8'>
    <script src='http://www.w3.org/Tools/respec/respec-w3c-common'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "unofficial",

          // the specification's short name, as in http://www.w3.org/TR/short-name/
          shortName:            "in-band-tracks",

          // if your specification has a subtitle that goes below the main
          // formal title, define it here
          // subtitle   :  "an excellent document",

          // if you wish the publication date to be other than the last modification, set this
          // publishDate:  "2009-08-06",

          // if the specification's copyright date is a range of years, specify
          // the start date here:
          // copyrightStart: "2005"

          // if there is a previously published draft, uncomment this and set its YYYY-MM-DD date
          // and its maturity status
          // previousPublishDate:  "1977-03-15",
          // previousMaturity:  "WD",

          // if there a publicly available Editor's Draft, this is the link
          edDraftURI:           "http://rawgit.com/silviapfeiffer/HTMLSourcingInbandTracks/master/index.html",

          // if this is a LCWD, uncomment and set the end of its review period
          // lcEnd: "2009-08-05",

          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                  name:       "Silvia Pfeiffer"
              ,   url:        "mailto:silviapfeiffer1@gmail.com"
              ,   mailto:     ""
              ,   company:    "NICTA"
              ,   companyURL: "http://nicta.com.au/"
              },
              {
                  name:       "Bob Lund"
              ,   url:        ""
              ,   mailto:     ""
              ,   company:    "CableLabs Inc"
              ,   companyURL: "http://www.cablelabs.com/"
              }
          ],

          // name of the WG
          wg:           "Inband Text Tracks Community Group",

          // URI of the public WG page
          wgURI:        "http://www.w3.org/community/inbandtracks/",

          // name (without the @w3c.org) of the public mailing to which comments are due
          wgPublicList: "public-inbandtracks",

          // URI of the patent status for this WG, for Rec-track documents
          // !!!! IMPORTANT !!!!
          // This is important for Rec-track documents, do not copy a patent URI from a random
          // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
          // Team Contact.
          wgPatentURI:  "",
          // !!!! IMPORTANT !!!! MAKE THE ABOVE BLINK IN YOUR HEAD

      };
    </script>
    <style type="text/css">
      table {
        border-collapse: collapse;
        border-style: hidden hidden none hidden;
      }
      table thead, table tbody {
        border-bottom: solid;
      }
      table td, table th {
        border-left: solid;
        border-right: solid;
        border-bottom: solid thin;
        vertical-align: top;
        padding: 0.2em;
      }
    </style>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification is provided to promote interoperability among implementations and users of in-band text tracks sourced for [[HTML5]]/[[HTML]] from media resource containers. The specification provides guidelines for the creation of video, audio and text tracks and their attribute values as mapped from in-band tracks from media resource types typically supported by User Agents. It also explains how the UA should map in-band text track content into text track cues.
      </p>
      <p>
        Mappings are defined for [[MPEGDASH]], [[ISOBMFF]], [[MPEG2TS]], [[OGGSKELETON]] and [[WebM]].
      </p>
    </section>

    <section id='sotd'>
      <p>
        This is the first draft. Please send feedback to: <a href="mailto:public-inbandtracks@w3.org">public-inbandtracks@w3.org</a>.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
        The specification maintains mappings from in-band audio, video and other data tracks of MIME-type/subtype media resources to HTML VideoTrack, AudioTrack, and TextTrack objects and their attribute values.
      </p>
      <p>
        A generic rule to follow is that a track as exposed in HTML only ever represents a single semantic concept. When mapping from a media resource, sometimes an in-band track does not relate 1-to-1 to a HTML text, audio or video track.
      </p>
      <p class="note">For example, a HTML TextTrack object is either a subtitle track or a caption track, never both. However, in-band text tracks may encapsulate caption and subtitle cues of the same language as a single in-band track. Since a caption track is essentially a subtitle track with additional cues of transcripts of audio-only information, such an encapsulation in a single in-band track can save space. In HTML, these tracks should be exposed as two TextTrack objects, since they represent different semantic concepts. The cues appear in their relevant tracks - subtitle cues would be present in both. This allows users to choose between the two tracks and activate the desired one in the same manner that they do when the two tracks are provided through two track elements.
      </p>
      <p class="note">
        A similar logic applies to in-band text tracks that have subtitle cues of different languages mixed together in one track. They, too, should be exposed in a track of their own language each.
      </p>
      <p class="note">
        A further example is when a UA decides to implement rendering for a caption track but without exposing the caption track through the TextTrack API. To the Web developer and the Web page user, such a video appears as though it has burnt-in captions. Therefore, the UA could expose two video tracks on the HTMLMediaElement - one with captions and a kind="captions" and one without captions with a kind="main". In this way, the user and the Web developer still get the choice of whether to see the video with or without captions.
      </p>
      <p>
        Another generic rule to follow for in-band data tracks is that in order to map them to TextTrack objects, they need to be mapped to media-time aligned cues that relate to a non-zero interval of time.
      </p>
      <p>
        For every MIME-type/subtype of an existing media container format, this specification defines the following information:
        <ol>
          <li>Track order.</li>
          <li>How to identify the type of tracks.</li>
          <li>Setting track attributes 'id', 'kind', 'language' and 'label' for sourced text tracks.</li>
          <li>Setting track attributes 'id', 'kind', 'language' and 'label' for sourced audio and video tracks.</li>
          <li>Mapping text track content into text track cues.</li>
        </ol>
      </p>
    </section>

    <section id='mpegdash'>
      <h2>MPEG DASH</h2>
      <b>MIME type/subtype: application/dash+xml</b>

      <ol>
        <li>Track Order
          <p>
            The order of tracks specified in the MPD (Media Presentation Description) format [[MPEGDASH]] is maintained when sourcing multiple MPEG DASH tracks into HTML.
          </p>
        </li>

        <li>Determining the type of track
          <p>
            A user agent recognises and supports data from a MPEG DASH media resource as being equivalent to a HTML track based on the adaptationSet mimeType:
            <ul>
              <li>text track: the mimeType is of main type "application" or "text"</li>
              <li>video track: the mimeType is of main type "video"</li>
              <li>audio track: the mimeType is of main type "audio"</li>
            </ul>
          </p>
        </li>

        <li>Track Attributes for sourced Text Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Content of the 'id' attribute in the AdaptationSet element. Empty string if 'id' attribute is not present.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <p>Given URN="urn:mpeg:dash:role:2011":</p>
                <ul>
                  <li>"captions": if the role descriptor's value is "caption"</li>
                  <li>"subtitles": if the role descriptor's value is "subtitle"</li>
                  <li>"metadata": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                The empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'lang' attribute in the AdaptationSet element.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Track Attributes for sourced Audio and Video Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Content of the 'id' attribute in the AdaptationSet element. Empty string if 'id' attribute is not present.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <p>Given a role scheme of "urn:mpeg:dash:role:2011", determine the 'kind' attribute from the value of the role descriptors in the AdaptationSet element.</p>
                <ul>
                  <li>"alternative": if the role is "alternate" but not also "main" or "commentary", or "dub"</li>
                  <li>"captions": if the role is "caption" and also "main"</li>
                  <li>"descriptions": if the role is "description" and also "supplementary"</li>
                  <li>"main": if the role is "main" but not also "caption", "subtitle", or "dub"</li>
                  <li>"main-desc": if the role is "main" and also "description"</li>
                  <li>"sign": not used</li>
                  <li>"subtitles": if the role is "subtitle" and also "main"</li>
                  <li>"translation": if the role is "dub" and also "main"</li>
                  <li>"commentary": if the role is "commentary" but not also "main"</li>
                  <li>"": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                The empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'lang' attribute in the AdaptationSet element.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Mapping text track content into text track cues
          <p>TBD</p>
        </li>
      </ol>

    </section>

    <section id='mpeg2ts'>
      <h2>MPEG-2 Transport Streams</h2>
      <b>MIME type/subtype: audio/mp2t , video/mp2t</b>

      <ol>
        <li>Track Order
          <p>
            Tracks are called "elementary streams" in a MPEG-2 Transport Stream (TS) [[MPEG2TS]]. The order in which elementary streams are listed in the "Program Map Table" (PMT) of a MPEG-2 TS is maintained when sourcing multiple MPEG-2 tracks into HTML.
          </p>
        </li>

        <li>Determining the type of track
          <p>
            A user agent recognises and supports data from a MPEG-2 TS resource as being equivalent to a HTML track based on the value of the 'stream_id' field of an elementary stream as given in a Transport or Program Stream header and which maps to a "stream type":
            <ul>
              <li>text track: the elementary stream with PID 0x02 or the stream type value is "0x02", "0x05" or between "0x80" and "0xFF"</li>
              <li>video track: the stream type value is "0x01", "0x02", "0x10", "0x1B", or between "0x1E" and "0x23"</li>
              <li>audio track: the stream type value is "0x03", "0x04", "0x0F", "0x11", or "0x1C"</li>
            </ul>
          </p>
        </li>

        <li>Track Attributes for sourced Text Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the elementary stream's identifier ('elementary_PID' field) in the PMT. In the case of CEA708 closed captions this will be the identifier of the video elementary stream containing captions in the Picture User Data.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <ul>
                  <li>"captions": if a "Caption Service Descriptor section" is present in a video elementary stream of stream type "0x02" and its 'cc_type' is 1 (True)</li><!-- see http://www.etherguidesystems.com/help/sdos/atsc/semantics/descriptors/CaptionService.aspx -->
                  <li>"subtitles": if the stream type value is "0x82"</li>
                  <li>"metadata": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                The empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'ISO_639_language_descriptor' field.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Track Attributes for sourced Audio and Video Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the elementary stream's identifier ('elementary_PID' field) in the PMT.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <ul>
                  <li>"alternative": not used</li>
                  <li>"captions": not used</li>
                  <li>"descriptions": AC3 audio in MPEG-2 TS: bsmod=2 and full_svc=0</li><!-- see http://www.atsc.org/cms/pdf/bootcamp/PSIP_Captions_rev2.pdf -->
                  <li>"main": first audio (video) elementary stream in the PMT</li>
                  <li>"main-desc": AC3 audio in MPEG-2 TS: bsmod=2 and full_svc=1</li>
                  <li>"sign": not used</li>
                  <li>"subtitles": not used</li>
                  <li>"translation": not first audio elementary stream in the PMT and bsmod=0</li>
                  <li>"commentary": not used</li>
                  <li>"": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                The empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'ISO_639_language_descriptor' field.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Mapping text track content into text track cues
          <p>
            MPEG-2 transport streams may contain data that should be exposed as cues on 'captions', 'subtitles' or 'metadata' text tracks. No data is defined that equates to 'descriptions' or 'chapters' text track cues.
          </p>
          <p>
            <ol type=a>
              <p>
              <li>Metadata cues
                <p>
                  Cues on an MPEG-2 metadata text track are created as DataCue objects [[HTML5]]. Each 'section' in an elementary stream identified as a text track creates a DataCue object with its TextTrackCue attributes sourced as follows:
                </p>
                <table>
                  <thead>
                    <th>Attribute</th>
                    <th>How to source its value</th>
                  </thead>
                  <tr>
                    <th>id</th>
                    <td>
                      Decimal representation of the 'table_id' in the first 8 bits of the 'section' data.
                    </td>
                  </tr>
                  <tr>
                    <th>startTime</th>
                    <td>
                      0
                    </td>
                  </tr>
                  <tr>
                    <th>endTime</th>
                    <td>
                      The time, in the media resource timeline, that corresponds to the presentation time of the video frame received immediately prior to the 'section' in the media resource.
                    </td>
                  </tr>
                  <tr>
                    <th>pauseOnExit</th>
                    <td>
                      'false'
                    </td>
                  </tr>
                  <tr>
                    <th>data</th>
                    <td>
                      The 'section_length' number of bytes immediately following the 'section_length' field in the 'section'.
                    </td>
                  </tr>
                </table>
              </li>
              </p>
              <p>
              <li>Captions cues
                <p>
                  MPEG-2 captions are in the CEA 708 format [[CEA708]] so cues on an MPEG-2 captions text track require an as yet to be specified CEA708Cue format to expose them, unless browsers want to map the CEA708 features into a WebVTTCue [[VTT708]].
                </p>
              </li>
              </p>
              <p>
              <li> Subtitles cues
                <p>
                  MPEG-2 subtitles are in the SCTE 27 format [[SCTE27]] so cues on an MPEG-2 subtitle text track require an as yet to be specified SCTE27Cue format to expose them, unless browsers want to map the SCTE 27 features into a WebVTTCue. This mapping process has not been defined.
                </p>
              </li>
              </p> 
            </ol>
          </p>
        </li>
      </ol>

    </section>

    <section id='mpeg4'>
      <h2>MPEG-4 ISOBMFF</h2>
      <b>MIME type/subtype: audio/mp4 , video/mp4</b>

      <ol>
        <li>Track Order
          <p>
            The order of tracks specified by TrackBox ('trak') boxes in the MovieBox ('moov') container [[ISOBMFF]] is maintained when sourcing multiple MPEG-4 tracks into HTML.
          </p>
        </li>

        <li>Determining the type of track
          <p>
            A user agent recognises and supports data from a MPEG-4 TrackBox as being equivalent to a HTML track based on the value of the 'handler_type' field in the HandlerBox ('hdlr) of the MediaBox ('mdia') of the TrackBox:
            <ul>
              <li>text track: the 'handler_type' value is "meta", "subt" or "text"</li>
              <li>video track: the 'handler_type' value is "soun"</li>
              <li>audio track: the 'handler_type' value is "vide"</li>
            </ul>
          </p>
        </li>

        <li>Track Attributes for sourced Text Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the 'track_ID' of a TrackHeaderBox ('tkhd') in a TrackBox ('trak').
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td><!-- see http://www.mp4ra.org/codecs.html -->
                <ul>
                  <li>"captions": 'handler_type' is "text" and the SampleEntry code ('format' field) is "tx3g" or "stpp"</li>
                  <li>"subtitles": 'handler_type' is "subt"</li>
                  <li>"metadata": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'name' field in the HandlerBox.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' field in the MediaHeaderBox.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Track Attributes for sourced Audio and Video Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the 'track_ID' of a TrackHeaderBox ('tkhd') in a TrackBox ('trak').
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <ul>
                  <li>"alternative": not used</li>
                  <li>"captions": not used</li>
                  <li>"descriptions": not used</li>
                  <li>"main": first audio (video) track</li>
                  <li>"main-desc": not used</li>
                  <li>"sign": not used</li>
                  <li>"subtitles": not used</li>
                  <li>"translation": not first audio (video) track</li>
                  <li>"commentary": not used</li>
                  <li>"": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'name' field in the HandlerBox.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' field in the MediaHeaderBox.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Mapping text track content into text track cues
          <p>TBD</p>
        </li>
      </ol>

    </section>

    <section id='webm'>
      <h2>WebM</h2>
      <b>MIME type/subtype: audio/webm , video/webm</b>

      <ol>
        <li>Track Order
          <p>
            The order of tracks specified in the EBML initialisation segment [[WebM]] is maintained when sourcing multiple WebM tracks into HTML.
          </p>
        </li>

        <li>Determining the type of track
          <p>
            A user agent recognises and supports data from a WebM resource as being equivalent to a HTML track based on the value of the 'TrackType' field of the track in the Segment info:
            <ul>
              <li>text track: 'TrackType' field is "0x11" or "0x21"</li>
              <li>video track: 'TrackType' field is "0x01"</li>
              <li>audio track: 'TrackType' field is "0x02"</li>
            </ul>
          </p>
        </li>

        <li>Track Attributes for sourced Text Tracks
          <p>
            WebM has defined how to store WebVTT [[WEBVTT]] files in WebM [[WEBM]][[WEBVTT-WEBM]]. Sourcing text tracks from WebM is different for chapter tracks from tracks of other kinds and is explained below the table.
          </p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the 'TrackNumber' field of the track in the "Track" section of the WebM file Segment.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <p>
                  Map the content of the 'TrackType' and 'CodecID' fields of the track as follows:
                </p>
                <ul>
                  <li>"captions": 'TrackType' is "0x11" and 'CodecId' is “D_WEBVTT/captions“</li>
                  <li>"subtitles": 'TrackType' is "0x11" and 'CodecId' is “D_WEBVTT/subtitles“</li>
                  <li>"descriptions": 'TrackType' is "0x11" and 'CodecId' is “D_WEBVTT/descriptions“</li>
                  <li>"metadata": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'name' field of the track.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' field of the track.
              </td>
            </tr>
          </table>
          <p>
          Tracks of kind "chapters" are found in the "Chapters" section of the WebM file Segment, which are all at the beginning of the WebM file, such that chapters can be used for navigation. The details of this mapping have not been specified yet and simply point to the more powerful Matroska chapter specification [[Matroska]]. Presumably, the 'id' attribute could be found in 'EditionUID', 'label' is empty, and 'language' can come from the first ChapterAtom's 'ChapLanguage' value.
          </p>
          <p class='note'>The Matroska container format, which is the basis for WebM, has specifications for other text tracks, in particular SRT, SSA/ASS, and VOBSUB. The described attribute mappings can be applied to these, too, except that the 'kind' field will always be "subtitles". The information of their 'CodecPrivate' field is exposed in the 'inBandMetadataTrackDispatchType' attribute.
          </p>
        </li>

        <li>Track Attributes for sourced Audio and Video Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Decimal representation of the 'TrackNumber' field of the track in the Segment info.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <ul>
                  <li>"alternative": not used</li>
                  <li>"captions": not used</li>
                  <li>"descriptions": not used</li>
                  <li>"main": the 'FlagDefault' element is set on the track</li>
                  <li>"main-desc": not used</li>
                  <li>"sign": not used</li>
                  <li>"subtitles": not used</li>
                  <li>"translation": not first audio (video) track</li>
                  <li>"commentary": not used</li>
                  <li>"": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'name' field of the track in the Segment info.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' field of the track in the Segment info.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Mapping text track content into text track cues
          <p>
            The only types of text tracks that WebM is defined for are in the WebVTT format [[WEBVTT-WEBM]]. Therefore, cues on a text track are created as VTTCue objects [[WEBVTT]]. Each 'Block' in the 'BlockGroup' of the WebM track that has the actual data of the text track creates a VTTCue object with its TextTrackCue attributes sourced as follows:
          </p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                First line of the Block's data.
              </td>
            </tr>
            <tr>
              <th>startTime</th>
              <td>
                Calculated from the 'BlockTimecode' field in the Block's header and the 'Timecode' field in the Cluster relative to which 'BlockTimecode' is specified.
              </td>
            </tr>
            <tr>
              <th>endTime</th>
              <td>
                Calculated from the 'BlockDuration' filed in the Block's header and the startTime.
              </td>
            </tr>
            <tr>
              <th>pauseOnExit</th>
              <td>
                'false'
              </td>
            </tr>
            <tr>
              <th>cue setting attributes</th>
              <td>
                Parsed from the second line of the Block's data.
              </td>
            </tr>
            <tr>
              <th>text</th>
              <td>
                The third and all following lines of the Block's data.
              </td>
            </tr>
          </table>
          <p class='note'>Other Matroska container format's text tracks can also be mapped to TextTrackCue objects. These will be created as DataCue objects with 'id', 'startTime', 'endTime', and 'pauseOnExit' attributes filled identically to the VTTCue objects, and the 'text' attribute containing the Block's data.
          </p>
        </li>
      </ol>

    </section>

    <section id='ogg'>
      <h2>Ogg</h2>
      <b>MIME type/subtype: audio/ogg , video/ogg</b>

      <ol>
        <li>Track Order
          <p>
            The order of tracks specified in the Skeleton fisbone headers [[OGGSKELETON]] is maintained when sourcing multiple Ogg tracks into HTML. If no Skeleton track is available, the order of the "beginning of stream" (BOS) pages which determines track order [[OGG]].
          </p>
        </li>

        <li>Determining the type of track
          <p>
            A user agent recognises and supports data from a Ogg resource as being equivalent to a HTML track based on the value of the 'role' field of the fisbone header in Ogg Skeleton:
            <ul>
              <li>text track:  'role' starts with "text"</li>
              <li>video track: 'role' starts with "video"</li>
              <li>audio track: 'role' starts with "audio"</li>
            </ul>
            If no Skeleton track is available, determine the type based on the codec used in the BOS pages, e.g. Vorbis is an "audio" track and "theora" is a video track.
          </p>
        </li>

        <li>Track Attributes for sourced Text Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Content of the 'name' message header field of the fisbone header in Ogg Skeleton. If no Skeleton header is available, use a decimal representation of the stream's serialnumber as given in the BOS.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <p>
                  Map the content of the 'role' message header fields of Ogg Skeleton as follows:
                </p>
                <ul>
                  <li>"captions": 'role' is "text/captions“</li>
                  <li>"subtitles": 'role' is "text/subtitle" or "text/karaoke“</li>
                  <li>"descriptions": 'role' is "text/textaudiodesc“</li>
                  <li>"chapters": 'role' is "text/chapters"</li>
                  <li>"metadata": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'title' message header field of the fisbone header. If no Skeleton header is available, the empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' message header field of the fisbone header. If no Skeleton header is available, the empty string.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Track Attributes for sourced Audio and Video Tracks
          <p>
          <table>
            <thead>
              <th>Attribute</th>
              <th>How to source its value</th>
            </thead>
            <tr>
              <th>id</th>
              <td>
                Content of the 'name' message header field of the fisbone header in Ogg Skeleton. If no Skeleton header is available, use a decimal representation of the stream's serialnumber as given in the BOS.
              </td>
            </tr>
            <tr>
              <th>kind</th>
              <td>
                <p>
                  Map the content of the 'role' message header fields of Ogg Skeleton as follows:
                </p>
                <ul>
                  <li>"alternative": 'role' is "audio/alternate" or "video/alternate"</li>
                  <li>"captions": 'role' is "video/captioned"</li>
                  <li>"descriptions": 'role' is "audio/audiodesc"</li>
                  <li>"main": 'role' is "audio/main" or "video/main"</li>
                  <li>"main-desc": 'role' is "audio/described"</li>
                  <li>"sign": 'role' is "video/sign"</li>
                  <li>"subtitles": 'role' is "video/subtitled"</li>
                  <li>"translation": 'role' is "audio/dub"</li>
                  <li>"commentary": 'role' is "audio/commentary"</li>
                  <li>"": otherwise</li>
                </ul>
              </td>
            </tr>
            <tr>
              <th>label</th>
              <td>
                Content of the 'title' message header field of the fisbone header. If no Skeleton header is available, the empty string.
              </td>
            </tr>
            <tr>
              <th>language</th>
              <td>
                Content of the 'language' message header field of the fisbone header. If no Skeleton header is available, the empty string.
              </td>
            </tr>
          </table>
          </p>
        </li>

        <li>Mapping text track content into text track cues
          <p>TBD</p>
        </li>
      </ol>

    </section>

    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
        Thanks to all In-band Track Community Group members in helping to create this specification.
      </p>
    </section>
  </body>
</html>
